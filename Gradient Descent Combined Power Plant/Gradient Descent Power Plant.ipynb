{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5]\n",
      " [ 4  6  8 10 12]\n",
      " [ 3  6  9 12 15]\n",
      " [ 8 12 16 20 24]\n",
      " [10 15 20 25 30]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7176, 5)\n",
      "(7176,)\n"
     ]
    }
   ],
   "source": [
    "# loading the training and testing data\n",
    "ccpp_train = np.genfromtxt('train.csv', delimiter = ',')\n",
    "x_train = ccpp_train[:, 0:ccpp_train.shape[1]-1]\n",
    "y_train = ccpp_train[:, ccpp_train.shape[1]-1]\n",
    "x_test = np.genfromtxt(\"test.csv\", delimiter = \",\")\n",
    "print(ccpp_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   8.58   38.38 1021.03   84.37  482.26]\n",
      " [  21.79   58.2  1017.21   66.74  446.94]\n",
      " [  16.64   48.92 1011.55   78.76  452.56]\n",
      " ...\n",
      " [  29.8    69.34 1009.36   64.74  437.65]\n",
      " [  16.37   54.3  1017.94   63.63  459.97]\n",
      " [  30.11   62.04 1010.69   47.96  444.42]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# printing the data\n",
    "print(ccpp_train)\n",
    "print(type(ccpp_train))\n",
    "# print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0      1        2      3\n",
      "0      8.58  38.38  1021.03  84.37\n",
      "1     21.79  58.20  1017.21  66.74\n",
      "2     16.64  48.92  1011.55  78.76\n",
      "3     31.38  71.32  1009.17  60.42\n",
      "4      9.20  40.03  1017.05  92.46\n",
      "...     ...    ...      ...    ...\n",
      "7171   9.32  37.73  1022.14  79.49\n",
      "7172  11.20  41.38  1021.65  61.89\n",
      "7173  29.80  69.34  1009.36  64.74\n",
      "7174  16.37  54.30  1017.94  63.63\n",
      "7175  30.11  62.04  1010.69  47.96\n",
      "\n",
      "[7176 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(x_train)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       38.38\n",
      "1       58.20\n",
      "2       48.92\n",
      "3       71.32\n",
      "4       40.03\n",
      "        ...  \n",
      "7171    37.73\n",
      "7172    41.38\n",
      "7173    69.34\n",
      "7174    54.30\n",
      "7175    62.04\n",
      "Name: 1, Length: 7176, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=4, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   8.58   38.38 1021.03   84.37]\n",
      " [  21.79   58.2  1017.21   66.74]\n",
      " [  16.64   48.92 1011.55   78.76]\n",
      " ...\n",
      " [  29.8    69.34 1009.36   64.74]\n",
      " [  16.37   54.3  1017.94   63.63]\n",
      " [  30.11   62.04 1010.69   47.96]]\n"
     ]
    }
   ],
   "source": [
    "print(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding dummy data to training data\n",
    "df = pd.DataFrame(x_train)\n",
    "N = x_train.shape[1]\n",
    "count =1\n",
    "for i in range(N):\n",
    "    for j in range(i, N):\n",
    "        df[count] = df[df.columns[i]] * df[df.columns[j]]\n",
    "        count += 1\n",
    "\n",
    "for i in range(N):\n",
    "    for j in range(i, N):\n",
    "        for k in range(j, N):\n",
    "            df[count] = df[df.columns[i]]*df[df.columns[j]]*df[df.columns[k]]\n",
    "            count += 1\n",
    "\n",
    "x_train = df.values\n",
    "\n",
    "# adding dummy data to testing data\n",
    "df = pd.DataFrame(x_test)\n",
    "N = x_test.shape[1]\n",
    "count =1\n",
    "for i in range(N):\n",
    "    for j in range(i, N):\n",
    "        df[count] = df[df.columns[i]] * df[df.columns[j]]\n",
    "        count += 1\n",
    "\n",
    "for i in range(N):\n",
    "    for j in range(i, N):\n",
    "        for k in range(j, N):\n",
    "            df[count] = df[df.columns[i]]*df[df.columns[j]]*df[df.columns[k]]\n",
    "            count += 1\n",
    "\n",
    "x_test = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature Scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step_gradient - find the new regression coefficients\n",
    "def step_gradient(x, y, learning_rate, m):\n",
    "    M = x.shape[0]\n",
    "    m_slope = (-2/M)*(((y - (x*m).sum(axis=1)).reshape(-1, 1))*x).sum(axis=0)\n",
    "    # brr = np.array([[1, 2, 3, 4, 5],[2,3,4,5,6],[1, 2, 3, 4, 5],[2,3,4,5,6],[2,3,4,5,6]])\n",
    "    # arr = np.array([[1], [2], [3], [4], [5]])\n",
    "    # print(arr*brr)\n",
    "    # print(((y - (x*m).sum(axis=1)).reshape(-1, 1)).shape)\n",
    "    # print(x.shape)\n",
    "    m = m - learning_rate * m_slope\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost - finding the error on trainig_data\n",
    "def cost(x, y, m):\n",
    "    # brr = np.array([[1, 2, 3, 4, 5],[2,3,4,5,6]])\n",
    "    # arr = np.array([1, 2, 3, 4, 5])\n",
    "    # print(brr*arr)\n",
    "    # print((brr*arr).sum(axis=0))\n",
    "    # print((brr*arr).sum(axis=1))\n",
    "    # #here axis is 1 for row as this axis is in numpy\n",
    "    # #whereas in genral axis=1 is for column as this axis is in pandas\n",
    "    return ((y - (x*m).sum(axis=1)) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic_gd - calculate regression coefficient with specified learning_rate and num_iterations\n",
    "def generic_gd(x, y, learning_rate, num_iterations):\n",
    "    m = np.zeros(x.shape[1])\n",
    "    for i in range(num_iterations):\n",
    "        m = step_gradient(x, y, learning_rate, m)\n",
    "        print(i, \"Cost :\", cost(x, y, m))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7176, 32)\n",
      "(7176, 1)\n",
      "0 Cost : 199316.62803392168\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "1 Cost : 192181.65286189417\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "2 Cost : 185319.71312602583\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "3 Cost : 178706.7686780351\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "4 Cost : 172330.75010614117\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "5 Cost : 166182.49187618188\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "6 Cost : 160253.70605348563\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "7 Cost : 154536.52311605553\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "8 Cost : 149023.38179800153\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "9 Cost : 143706.99688983784\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "10 Cost : 138580.34466178046\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "11 Cost : 133636.65247373437\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "12 Cost : 128869.3895724245\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "13 Cost : 124272.2583990199\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "14 Cost : 119839.18624785978\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "15 Cost : 115564.31723231214\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "16 Cost : 111442.00453978844\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "17 Cost : 107466.80296401307\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "18 Cost : 103633.4617042835\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "19 Cost : 99936.91742209315\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "20 Cost : 96372.2875458934\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "21 Cost : 92934.86381511597\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "22 Cost : 89620.10605489629\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "23 Cost : 86423.63617324762\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "24 Cost : 83341.23237272947\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "25 Cost : 80368.82356893996\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "26 Cost : 77502.48400843612\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "27 Cost : 74738.4280789506\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "28 Cost : 72073.0053050293\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "29 Cost : 69502.69552245963\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "30 Cost : 67024.10422509749\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "31 Cost : 64633.95807792882\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "32 Cost : 62329.10059042314\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "33 Cost : 60106.48794444836\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "34 Cost : 57963.18497122203\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "35 Cost : 55896.3612719711\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "36 Cost : 53903.28747716357\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "37 Cost : 51981.33163935887\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "38 Cost : 50127.95575490105\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "39 Cost : 48340.712409849846\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "40 Cost : 46617.241545709476\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "41 Cost : 44955.26734067335\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "42 Cost : 43352.59520225707\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "43 Cost : 41807.10886733854\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "44 Cost : 40316.76760576734\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "45 Cost : 38879.60352384223\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "46 Cost : 37493.7189640884\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "47 Cost : 36157.28399789327\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "48 Cost : 34868.53400768319\n",
      "(7176, 32)\n",
      "(7176, 1)\n",
      "49 Cost : 33625.7673554416\n",
      "[-3.88180231e+00 -2.96861623e+00 -2.11841446e+00 -1.39338590e+00\n",
      " -7.99234883e-01 -1.39338590e+00 -7.99234883e-01 -3.22074672e-01\n",
      " -3.22074672e-01  5.67760462e-02  3.55287727e-01 -2.11841446e+00\n",
      " -1.39338590e+00 -7.99234883e-01 -3.22074672e-01 -7.99234883e-01\n",
      " -3.22074672e-01  5.67760462e-02  5.67760462e-02  3.55287727e-01\n",
      "  5.88970931e-01 -3.22074672e-01  5.67760462e-02  3.55287727e-01\n",
      "  3.55287727e-01  5.88970931e-01  7.70605305e-01  5.88970931e-01\n",
      "  7.70605305e-01  9.10500848e-01  1.01690318e+00  2.71181869e+02]\n"
     ]
    }
   ],
   "source": [
    "# run - run gradient descent on training data\n",
    "def run(x, y):\n",
    "    df = pd.DataFrame(x)\n",
    "    df[x.shape[1]] = 1\n",
    "    x = df.values\n",
    "    learning_rate = 0.009\n",
    "    num_iterations = 50\n",
    "    m = generic_gd(x, y, learning_rate, num_iterations)\n",
    "    print(m)\n",
    "    return m\n",
    "m = run(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict - predicting values for x_test\n",
    "def predict(x,m):\n",
    "    return (x*m).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[286.05262866 285.92163677 255.54829887 ... 262.87032496 265.12481217\n",
      " 269.52912406]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(x_test)\n",
    "df[x_test.shape[1]] = 1\n",
    "x_test = df.values\n",
    "y_pred = predict(x_test, m)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Predictions_ccpp.csv',y_pred, fmt = \"%.8f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9cd6022e10ffee125c9e0ed759adc45437dbe9c21820c7c05ae2ab5c7b42193a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
