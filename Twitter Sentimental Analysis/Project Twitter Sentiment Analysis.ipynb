{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\python38\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python38\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\python38\\lib\\site-packages (from pandas) (1.22.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python38\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python38\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: nltk in c:\\python38\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\python38\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\python38\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\python38\\lib\\site-packages (from nltk) (4.63.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\python38\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: colorama in c:\\python38\\lib\\site-packages (from click->nltk) (0.4.3)\n",
      "Requirement already satisfied: sklearn in c:\\python38\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\python38\\lib\\site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python38\\lib\\site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\python38\\lib\\site-packages (from scikit-learn->sklearn) (1.22.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\python38\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\python38\\lib\\site-packages (from scikit-learn->sklearn) (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import pos_tag\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "!pip install sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 tweet_id airline_sentiment     airline  \\\n",
      "0      567900433542488064          negative   Southwest   \n",
      "1      569989168903819264          positive   Southwest   \n",
      "2      568089179520954368          positive      United   \n",
      "3      568928195581513728          negative   Southwest   \n",
      "4      568594180014014464          negative      United   \n",
      "...                   ...               ...         ...   \n",
      "10975  569934458364813313           neutral    American   \n",
      "10976  568564006329434113          positive      United   \n",
      "10977  569643648910028801          negative  US Airways   \n",
      "10978  568864981917110272          negative  US Airways   \n",
      "10979  568929299350179840          negative      United   \n",
      "\n",
      "      airline_sentiment_gold           name negativereason_gold  \\\n",
      "0                        NaN  ColeyGirouard                 NaN   \n",
      "1                        NaN  WalterFaddoul                 NaN   \n",
      "2                        NaN      LocalKyle                 NaN   \n",
      "3                        NaN    amccarthy19                 NaN   \n",
      "4                        NaN        J_Okayy                 NaN   \n",
      "...                      ...            ...                 ...   \n",
      "10975                    NaN  Cottopanama85                 NaN   \n",
      "10976                    NaN   PaulBEsteves                 NaN   \n",
      "10977                    NaN    runfixsteve                 NaN   \n",
      "10978                    NaN     CLChicosky                 NaN   \n",
      "10979                    NaN     JW_Blocker                 NaN   \n",
      "\n",
      "       retweet_count                                               text  \\\n",
      "0                  0  @SouthwestAir I am scheduled for the morning, ...   \n",
      "1                  0  @SouthwestAir seeing your workers time in and ...   \n",
      "2                  0  @united Flew ORD to Miami and back and  had gr...   \n",
      "3                  0     @SouthwestAir @dultch97 that's horse radish üò§üê¥   \n",
      "4                  0  @united so our flight into ORD was delayed bec...   \n",
      "...              ...                                                ...   \n",
      "10975              0                            @AmericanAir followback   \n",
      "10976              0  @united thanks for the help. Wish the phone re...   \n",
      "10977              0  @usairways the. Worst. Ever. #dca #customerser...   \n",
      "10978              0  @nrhodes85: look! Another apology. DO NOT FLY ...   \n",
      "10979              1  @united you are by far the worst airline. 4 pl...   \n",
      "\n",
      "      tweet_coord              tweet_created              tweet_location  \\\n",
      "0             NaN  2015-02-17 20:16:29 -0800             Washington D.C.   \n",
      "1             NaN  2015-02-23 14:36:22 -0800  Indianapolis, Indiana; USA   \n",
      "2             NaN  2015-02-18 08:46:29 -0800                    Illinois   \n",
      "3             NaN  2015-02-20 16:20:26 -0800                         NaN   \n",
      "4             NaN  2015-02-19 18:13:11 -0800                         NaN   \n",
      "...           ...                        ...                         ...   \n",
      "10975         NaN  2015-02-23 10:58:58 -0800                 ohio,panama   \n",
      "10976         NaN  2015-02-19 16:13:17 -0800                    Brooklyn   \n",
      "10977         NaN  2015-02-22 15:43:24 -0800      St. Augustine, Florida   \n",
      "10978         NaN  2015-02-20 12:09:15 -0800                         NaN   \n",
      "10979         NaN  2015-02-20 16:24:49 -0800                         NaN   \n",
      "\n",
      "                    user_timezone  \n",
      "0          Atlantic Time (Canada)  \n",
      "1      Central Time (US & Canada)  \n",
      "2      Central Time (US & Canada)  \n",
      "3          Atlantic Time (Canada)  \n",
      "4      Eastern Time (US & Canada)  \n",
      "...                           ...  \n",
      "10975                         NaN  \n",
      "10976  Eastern Time (US & Canada)  \n",
      "10977                         NaN  \n",
      "10978                         NaN  \n",
      "10979                         NaN  \n",
      "\n",
      "[10980 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text airline_sentiment\n",
      "0      @SouthwestAir I am scheduled for the morning, ...          negative\n",
      "1      @SouthwestAir seeing your workers time in and ...          positive\n",
      "2      @united Flew ORD to Miami and back and  had gr...          positive\n",
      "3         @SouthwestAir @dultch97 that's horse radish üò§üê¥          negative\n",
      "4      @united so our flight into ORD was delayed bec...          negative\n",
      "...                                                  ...               ...\n",
      "10975                            @AmericanAir followback           neutral\n",
      "10976  @united thanks for the help. Wish the phone re...          positive\n",
      "10977  @usairways the. Worst. Ever. #dca #customerser...          negative\n",
      "10978  @nrhodes85: look! Another apology. DO NOT FLY ...          negative\n",
      "10979  @united you are by far the worst airline. 4 pl...          negative\n",
      "\n",
      "[10980 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train[['text', 'airline_sentiment']]\n",
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['@SouthwestAir I am scheduled for the morning, 2 days after the fact, yes..not sure why my evening flight was the only one Cancelled Flightled'\n",
      "  'negative']\n",
      " ['@SouthwestAir seeing your workers time in and time out going above and beyond is why I love flying with you guys. Thank you!'\n",
      "  'positive']\n",
      " ['@united Flew ORD to Miami and back and  had great crew, service on both legs. THANKS'\n",
      "  'positive']\n",
      " ...\n",
      " ['@usairways the. Worst. Ever. #dca #customerservice' 'negative']\n",
      " ['@nrhodes85: look! Another apology. DO NOT FLY @USAirways' 'negative']\n",
      " ['@united you are by far the worst airline. 4 plane delays on 1 round trip flight. How is that possible.'\n",
      "  'negative']]\n"
     ]
    }
   ],
   "source": [
    "training_data = df_train.values\n",
    "print(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliiting the Tweet text into words using NLTK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train = []\n",
    "for i in range(len(training_data)):\n",
    "    tweets_train.append([word_tokenize(training_data[i][0]), training_data[i][1]])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Words using WordNetLemmatizer available in NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n",
    "stops.update(punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "def get_simple_pos(tag):\n",
    "    \n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def clean_tweets(words):\n",
    "    output_words = []\n",
    "    for w in words:\n",
    "        if w.isalpha():\n",
    "            if w.lower() not in stops:\n",
    "                pos = pos_tag([w])\n",
    "                #print(pos)\n",
    "                clean_word = lemmatizer.lemmatize(w, pos = get_simple_pos(pos[0][1]))\n",
    "                output_words.append(clean_word.lower())\n",
    "    return output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tweets_train)):\n",
    "    tweets_train[i] = (clean_tweets(tweets_train[i][0]), tweets_train[i][1])\n",
    "#print(tweets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "tweets = []\n",
    "for tweet, sentiment in tweets_train:\n",
    "    tweets.append(\" \".join(tweet))\n",
    "    y_train.append(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Count Vectorizer to get the X Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/using-countvectorizer-to-extracting-features-from-text/\n",
    "count_vec = CountVectorizer(max_features=2000) # Tried using n grams but the accuracy was decreasing\n",
    "x_train_features = count_vec.fit_transform(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepaing Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = np.array(df_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test = []\n",
    "for t in testing_data:\n",
    "    t = clean_tweets(word_tokenize(t))\n",
    "    tweets_test.append(\" \".join(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_features = count_vec.transform(tweets_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(x_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svc.predict(x_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_pred_svm)\n",
    "df.to_csv('predictions_svm.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(x_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_pred_rf)\n",
    "df.to_csv('predictions_rf.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnv = MultinomialNB(alpha = 1)\n",
    "mnv.fit(x_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mnv = mnv.predict(x_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_pred_mnv)\n",
    "df.to_csv('predictions_mnv.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(x_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt = dt.predict(x_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_pred_dt)\n",
    "df.to_csv('predictions_dt.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It was found that Multinomial Naive Bayes was performing the best among the above classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
